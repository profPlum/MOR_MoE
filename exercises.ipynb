{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a739cfb-cab7-4b20-bfbb-e7e6820dddb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=0\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pytorch_lightning as L\n",
    "import torch.nn.functional as F\n",
    "torch.set_float32_matmul_precision('medium')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57608558-30e5-4083-8d88-bae1c3a01cd3",
   "metadata": {},
   "source": [
    "# Exercise 3\n",
    "\n",
    "Use POU-Net with neural operators to fit the following functional data. Working in the unit circle domain, $\\Omega = \\{x \\in \\mathbb{R}^2 : x\\leq 1\\}$, the true operator maps functions on $\\Omega$ to functions on $\\Omega$ where the both the input and output functions vanish at the boundaries of the domain. This situation is common when trying to model physical systems, e.g., the flow at the blade of a wind turbine can be assumed to be zero, but the flow elsewhere needs to be modeled. We call the details of the field behavior at the boundaries the boundary conditions.\n",
    "\n",
    "We'll be working with an operator learning method we developed called MOR-Physics. See https://arxiv.org/pdf/1810.08552 and https://www.sciencedirect.com/science/article/pii/S004578252030685X. It's very similar to FNO. Try implementing it as described in the papers. The formula for the action of the parameterized operator is,\n",
    "$$\n",
    "\\mathcal{N}(u) = \\mathcal{F^{-1}}\\left(g(\\mathbf{\\kappa}) \\mathcal{F} (h(u)) \\right)\n",
    "$$\n",
    "where $\\mathcal{F}$ is the fourier transform, $g$ is a complex valued function of the wave vector $\\kappa$, and $h$ is a point-wise nonlinearity.\n",
    "\n",
    "Since the method is Fourier based, it only works for periodic domains, while the domain for the data is the unit circle. We can still work on the periodic domain and use MOR-Physics by embedding the circle inside a periodic domain and and use mixture of experts to fit the operator in the domain while mapping the region outside the domain to zero. See this paper for more details and generalizations of this approach in the context of numerical methods for solving PDEs, https://www.sciencedirect.com/science/article/pii/S0021999114000151\n",
    "\n",
    "Try using MOR-physics to fit the operator in the unit circle while having it vanish outside. There's a few different levels of complexity you could try here. You could start off by fixing the POU's to be the unit circle and the region outside the circle and also fix the experts to be MOR-Physics inside the circle and the zero operator outside. Next you could try letting the POU's adopt to the domain and/or choosing between several MOR-Physics experts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275cc79e-b299-441f-a9fb-e8f0de1463e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "u_train = np.load('data/u_train.npy')\n",
    "v_train = np.load('data/v_train.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174561f5-23c6-4bea-b06d-35f6a9a6a112",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this plots a sample of the input functions. Note the domain boundary in red\n",
    "fig,ax = plt.subplots(1,1)\n",
    "plt.imshow(u_train[5],extent=[-1.25,1.25,-1.25,1.25])\n",
    "ax.add_patch(plt.Circle((0, 0), 1, ec='r',fc=[0,0,0,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6d2382-d1e9-4237-9bb5-984af659a477",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this plots a sample of the output functions. Note the domain boundary in red\n",
    "fig,ax = plt.subplots(1,1)\n",
    "plt.imshow(v_train[5],extent=[-1.25,1.25,-1.25,1.25])\n",
    "plt.colorbar()\n",
    "ax.add_patch(plt.Circle((0, 0), 1, ec='r',fc=[0,0,0,0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f9012a7-1f24-4eaa-8055-8ad9b86bc93a",
   "metadata": {},
   "source": [
    "### Wave function g hermitian symmetry:\n",
    "In order for IFFT to give real results we need $ g(-\\kappa)=\\overline {g(\\kappa)}$ \\\n",
    "Or you can just take real part after IFFT..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863455ed-3c97-4a5d-a799-71f7caf3bb18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightning_utils import *\n",
    "from MOR_Operator import MOR_Operator\n",
    "from POU_net import POU_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4761e68-21cd-4eaf-b9b8-f223cd31769f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    print(torch.fft.fftfreq(i+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f0426a-b916-47d1-bbf5-2a23fee248db",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "u_train = torch.as_tensor(u_train).float()\n",
    "v_train = torch.as_tensor(v_train).float()\n",
    "dataset = torch.utils.data.TensorDataset(u_train[:,None], v_train[:,None])\n",
    "#train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, drop_last=True)\n",
    "train, val = torch.utils.data.random_split(dataset, [0.8, 0.2])\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size=batch_size, drop_last=True)\n",
    "val_loader = torch.utils.data.DataLoader(val, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1447eea9-b9f0-4857-b391-536a82c74968",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "X, y = next(iter(train_loader))\n",
    "print(f'{X.shape=}, {y.shape=}')\n",
    "\n",
    "i = random.randrange(len(X))\n",
    "print(f'id={i}')\n",
    "\n",
    "plt.figure(1)\n",
    "plt.imshow(X[i].squeeze())\n",
    "plt.colorbar()\n",
    "plt.figure(2)\n",
    "plt.imshow(y[i].squeeze())\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8162c83c-5ce3-48fc-a2ea-e8924eedf161",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0789cf9-0d80-4d99-a63a-563236ce192a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,6):\n",
    "    print(torch.fft.fftshift(torch.fft.fftfreq(i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5e9854-be94-42ba-a8f3-6339d2f95764",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6dbf7d-ba58-42ff-a8f2-df180d4a8e3b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%pdb\n",
    "#import torch\n",
    "#torch.multiprocessing.set_start_method('spawn') # good solution !!!!\n",
    "torch.use_deterministic_algorithms(False)\n",
    "torch.manual_seed(0)\n",
    "\n",
    "#Expert = lambda **kwd_args: MOR_Operator(n_layers=1, **kwd_args) # works b/c only 1 layer\n",
    "#Expert = MOR_Operator # works (with 32 modes)\n",
    "#Expert = lambda *args, **kwd_args: MOR_Operator(*args, **kwd_args, k_modes=16, mlp_second=True) # only kind of works?\n",
    "#Expert = CNN # works\n",
    "\n",
    "from POU_net import FieldGatingNet\n",
    "\n",
    "# The gating net seems to need to have full modes to make the MoE work much better\n",
    "# but it still results in some compute savings.\n",
    "gating_net = lambda *args, **kwd_args: FieldGatingNet(*args, **(kwd_args | {'k':5, 'k_modes':32, 'n_layers':12, 'noise_sd': 0.0}))\n",
    "\n",
    "# train model\n",
    "model = POU_net(1, 1, 100, lr=0.001, T_max=10, make_gating_net=gating_net,\n",
    "                k_modes=16, mlp_second=True)\n",
    "trainer = L.Trainer(max_epochs=1000, accelerator='gpu', devices=1)\n",
    "trainer.fit(model=model, train_dataloaders=train_loader, val_dataloaders=val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af2dbbc-dc68-4c96-af7c-5726600aac50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchmetrics\n",
    "x = torchmetrics.ExplainedVariance()\n",
    "x.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d228784-9d48-4429-8a96-beb11cb1cd16",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = trainer.progress_bar_metrics\n",
    "print(x)\n",
    "print(type(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06af710-06c8-4fec-8957-9c4fe8feb351",
   "metadata": {},
   "source": [
    "$$NLL_{scalar_i}=(\\mu_i-y_i)^2/(2\\sigma_i^2)+ln(\\sigma_i)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7be5658-af56-42dc-9b07-6d217bd2f69a",
   "metadata": {},
   "source": [
    "### The 2nd Phase is Very Important!\n",
    "Despite the exponential decay, I'm not entirely sure why (because I've verified again that L2 decay works).\n",
    "But at least part of the reason is because it restarts the learning rate schedulers and the Adam adaptive learning rates too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253aa46b-eb20-4eb6-bf46-7efac18f0d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = L.Trainer(max_epochs=1000, accelerator='gpu', devices=1)\n",
    "trainer.fit(model=model, train_dataloaders=train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74fc956-0020-488e-beb9-e1fa3e70ed7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c011e559-388c-4cda-92bf-2a2b59d04b46",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainer.validate(model, dataloaders=train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a60ac6-91c4-4134-a5b4-1f8a4e0ee650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This display loop, Verified to work 7/19/24\n",
    "shuffle_loader = torch.utils.data.DataLoader(train_dataset, shuffle=True)\n",
    "model.eval()\n",
    "\n",
    "for i, datum in enumerate(shuffle_loader):\n",
    "    if i>10: break\n",
    "    X, y = datum\n",
    "    plt.figure(1+i*3)\n",
    "    plt.imshow(X.squeeze())\n",
    "    plt.colorbar()\n",
    "    plt.title('Input')\n",
    "    \n",
    "    plt.figure(2+i*3)\n",
    "    plt.imshow(y.squeeze())\n",
    "    plt.colorbar()\n",
    "    plt.title('Truth')\n",
    "    \n",
    "    plt.figure(3+i*3)\n",
    "    plt.imshow(model(X.cuda()).cpu().detach().squeeze())\n",
    "    plt.colorbar()\n",
    "    plt.title('Pred')\n",
    "    plt.show()\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5641d8c-18a4-4981-b487-da96cf87597a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(torch.cuda.memory_summary())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
