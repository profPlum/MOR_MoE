{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71861422-d351-4c20-84ef-657a5b175bed",
   "metadata": {},
   "source": [
    "# Setup:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458919a7-9007-4d9d-95ea-95386b12eb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pytorch_lightning as L\n",
    "import torch.nn.functional as F\n",
    "import torch.multiprocessing\n",
    "torch.multiprocessing.set_sharing_strategy('file_system')\n",
    "\n",
    "from lightning_utils import *\n",
    "from utils import *\n",
    "from MOR_Operator import MOR_Operator\n",
    "from POU_net import POU_net\n",
    "import JHTDB_sim_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31bb2d28-3ea5-4a2d-a278-395fe942cf02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_eval_backend import *\n",
    "\n",
    "ablation_models = ['Everything-large', # 0\n",
    "                   'Everything-small', # 1\n",
    "                   'Control-small', # 2\n",
    "                   'Control-No-Output-LN', # 3\n",
    "                   'MixtureOfExperts-normalized-small', # 4\n",
    "                   'MixtureOfExperts-small', # 5\n",
    "                   'RecursiveSteps-small', # 6\n",
    "                   'CNN-small-k4', # 7\n",
    "                   'Everything-small-k4', # 8\n",
    "                   'WNO-800-epochs', # 9\n",
    "                   'Everything-WNO-stride-800-epochs', #10\n",
    "                  ]\n",
    "ablation_model_index = 1\n",
    "model_name = ablation_models[ablation_model_index]\n",
    "\n",
    "optional_model_kwd_args = {}\n",
    "if 'CNN' in model_name:\n",
    "    print('using CNN experts')\n",
    "    optional_model_kwd_args['make_expert'] = CNN\n",
    "    optional_model_kwd_args['skip_connections']=True\n",
    "\n",
    "model = load_model(f'./lightning_logs/paper/{model_name}/last.ckpt', **optional_model_kwd_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc3625f-cc99-4437-82cb-bc3f72be3503",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = JHTDB_sim_op.JHTDB_Channel('data/turbulence_output', time_chunking=5)\n",
    "val_data_loader = torch.utils.data.DataLoader(val_dataset, batch_size=5, num_workers=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd658932-4b37-43c3-a945-b70798fefa0d",
   "metadata": {},
   "source": [
    "# Predictive Simulation Based Calibration (aka PSBC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6fb063-2a9b-47c5-8fa7-fbfe379b98b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import model_agnostic_BNN\n",
    "from model_agnostic_BNN import get_BNN_pred_distribution, clear_cache\n",
    "\n",
    "# Adapted to create a pytorch mixture distribution\n",
    "def get_BNN_pred_GMM_distribution(bnn_model, x_input, n_samples=100, **kwd_args):\n",
    "    '''\n",
    "    If you just want moments use get_BNN_pred_moments() instead as it is *much* more memory efficient (e.g. for large sample sizes).\n",
    "    But this is still useful if you want an actual distribution.\n",
    "    '''\n",
    "    \n",
    "    # get sample aleatoric distributions from sampling epistemic distribution\n",
    "    pred_distribution = get_BNN_pred_distribution(model, inputs, n_samples=n_samples_per_batch)\n",
    "    pred_distribution = torch.distributions.normal.Normal(*pred_distribution, validate_args=False)\n",
    "    mix = torch.distributions.Categorical(torch.ones(len(pred_distribution[0]),)) # uniform weights\n",
    "    pred_distribution = torch.distributions.MixtureSameFamily(mix, pred_distribution)\n",
    "    return pred_distribution\n",
    "\n",
    "import numpy as np\n",
    "dumb_vmap = lambda func: lambda X: torch.stack([func(x) for x in X])\n",
    "# useful for debugging when vmap won't work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51577e62-2a7a-4a78-9e2f-f3021a4baeda",
   "metadata": {},
   "source": [
    "## ALeatoric KDE Equations:\n",
    "\n",
    "1. We want to take the union of the centroid pdfs so we sum. But then we need to make the pdf integrate to 1 $\\int_{x \\in \\Omega} p(x) dx=1$, so we divide by the number of pdfs resulting in an average: $$p(S_{jk})={1\\over N}\\sum^N_{i=0}p_{ik}(S_{jk}) \\text{ s.t. } S_{jk}\\sim p_{jk}$$\n",
    "2. However all these computations need to happen in the log domain for numerical stability: $$log(p(S_{jk}))=log({1\\over N}\\sum^N_{i=0}p_{ik}(S_{jk}))=log(\\sum^N_{i=0}p_{ik}(S_{jk}))-log(N)$$\n",
    "4. In practice this requires the Log-sum-exp trick (aka LSE): $$log(p(S_{jk}))={LSE}^N_{i=0}log(p_{ik}(S_{jk}))-log(N)$$\n",
    "5. Then we need to get the joint pdf across all the spatial dimension(s) (indexed by k) $$log(p(S_j))=\\sum_k log(p(S_{jk}))$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f92ac51f-3126-43cd-a086-407a27a25593",
   "metadata": {},
   "source": [
    "### Mixture Distribution Code Example:\n",
    "\n",
    "```\n",
    "mix = D.Categorical(torch.ones(5,))\n",
    "comp = D.Normal(torch.randn(5,), torch.rand(5,))\n",
    "gmm = MixtureSameFamily(mix, comp)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad62986-d2ab-4866-8f6a-78a12fcebc1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GOTCHA: It seems the problem is that it always gives more liklihood to the true value than the samples? Maybe just sample more?\n",
    "# That wouldn't be all bad if it were actually true it would imply that the true value always has the highest likelihood but it can't be literally true...\n",
    "def _find_batch_BCI_truth_quantiles(model, inputs, outputs, n_samples_per_batch, chunk_size=25, fake_ideal=False, verbose=True):\n",
    "    with torch.inference_mode():\n",
    "        # get sample aleatoric distributions from sampling epistemic distribution\n",
    "        pred_distribution = get_BNN_pred_distribution(model, inputs, n_samples=n_samples_per_batch)\n",
    "        pred_distribution = torch.distributions.normal.Normal(*pred_distribution, validate_args=False)\n",
    "        pred_samples = pred_distribution.sample() # then sample the actual predictions from the sampled aleatoric distributions\n",
    "        if verbose: print('pred_samples.shape:', pred_samples.shape) # shape==[aleatoric_sample, batch, ...]\n",
    "\n",
    "        def get_log_density(sample_datum): # does this still work with the mixture?\n",
    "            ''' gets log density of a single sample given the aleatoric distributions sampled from the epistemic weights '''\n",
    "            # averaged_pdfs = p(S_jk) = (1/N)∑_i(p_ik(S_jk)) s.t. S_jk ~ p_jk := KDE-style pdf (derived from aleatoric distributions)\n",
    "            averaged_pdfs = torch.logsumexp(pred_distribution.log_prob(sample_datum), dim=0) - np.log(n_samples_per_batch) # average across epistemic dimension\n",
    "            joint_pdfs = torch.vmap(torch.sum)(averaged_pdfs) # joint pdf across all non-batch dims := log(∏_ip_i(S_i))\n",
    "            return joint_pdfs\n",
    "\n",
    "        # vmap supports additional input dimension: j (aka aleatoric sample dimension)\n",
    "        #vget_log_density = dumb_vmap(get_log_density)\n",
    "        vget_log_density = torch.vmap(get_log_density, chunk_size=chunk_size)\n",
    "        pred_samples = pred_samples[:, None] # move the aleatoric sample dimension out of the epistemic sample distribution dimension\n",
    "        assert tuple(pred_samples.shape)[:3]==(n_samples_per_batch, 1, inputs.shape[0])\n",
    "        pred_joint_log_pdfs = vget_log_density(pred_samples) # shape==[aleatoric_sample, batch]\n",
    "        assert tuple(pred_joint_log_pdfs.shape)==(n_samples_per_batch, inputs.shape[0])\n",
    "        \n",
    "        import random # Verified that fake ideal works: 10/10/24\n",
    "        if fake_ideal: # artificially simulate the ideal case where outputs are sampled from prediction distribution\n",
    "            outputs = random.choice(pred_samples) # GOTCHA: isn't realized with small number of batches & sample sizes!\n",
    "\n",
    "        truth_joint_log_pdf = get_log_density(outputs[None])\n",
    "        assert tuple(truth_joint_log_pdf.shape)==(inputs.shape[0],)\n",
    "\n",
    "        if verbose:\n",
    "            # plot the pdf quantile distribution(s)\n",
    "            batch_display_ids = random.choices(range(inputs.shape[0]), k=1)\n",
    "            for i in batch_display_ids:\n",
    "                plt.hist(pred_joint_log_pdfs[:,i].cpu(), color='blue')\n",
    "                plt.axvline(truth_joint_log_pdf[i].item(), color='red')\n",
    "                plt.title(f'{i}th joint-log-pdf Distribution')\n",
    "                plt.show()\n",
    "\n",
    "        pdf_comparison = pred_joint_log_pdfs<=truth_joint_log_pdf\n",
    "        if verbose: print(f'pdf_comparison={list(pdf_comparison.ravel().cpu().numpy())}')\n",
    "        truth_quantiles = torch.sum(pdf_comparison, dim=0)/pdf_comparison.shape[0]\n",
    "        assert pred_joint_log_pdfs.shape[0]==pdf_comparison.shape[0]==n_samples_per_batch\n",
    "        return truth_quantiles.cpu().detach()\n",
    "\n",
    "# Actually we don't need KDE! We can use the aleatoric uncertainty to get density directly!\n",
    "def find_BCI_truth_quantiles(model, data_loader, n_batches=100, n_samples_per_batch=25, chunk_size=25, fake_ideal=False, verbose=True):\n",
    "    \"\"\"\n",
    "    These quantiles should follow q~U(0,1) in order for BCI theory to be satisfied.\n",
    "    You can simulate the ideal case as a sanity check with fake_ideal=True.\n",
    "    GOTCHA: In practice with small batch and/or sample sizes even with fake_ideal=True, the distribution will not look uniform!\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    assert model.device.type=='cuda' # TOO slow on cpu\n",
    "    truth_quantiles = []\n",
    "    while len(truth_quantiles)<n_batches:\n",
    "        for inputs, outputs in data_loader:\n",
    "            if len(truth_quantiles)==0: print(f'{inputs.shape=}, {outputs.shape=}')\n",
    "            elif len(truth_quantiles)==n_batches: break\n",
    "            print(f'processing batch: {len(truth_quantiles)}')\n",
    "            truth_quantiles.append(_find_batch_BCI_truth_quantiles(model, inputs.to(model.device), outputs.to(model.device),\n",
    "                                                                   n_samples_per_batch=n_samples_per_batch, fake_ideal=fake_ideal,\n",
    "                                                                   chunk_size=chunk_size, verbose=verbose))\n",
    "\n",
    "    truth_quantiles = torch.cat(truth_quantiles)\n",
    "    display_quantiles = list(torch.quantile(truth_quantiles, q=torch.linspace(0.0,1.0, steps=5)).numpy())\n",
    "    print('1/5th quantiles of truth quantile distribution: ', display_quantiles)\n",
    "    plt.hist(truth_quantiles)\n",
    "    plt.title('Truth Quantiles (Should follow q~U(0,1))')\n",
    "    plt.show()\n",
    "    return truth_quantiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0fff30-a765-4048-aee3-ba909f92a024",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pdb on\n",
    "truth_quantiles = find_BCI_truth_quantiles(model, val_data_loader, n_batches=10, n_samples_per_batch=25, fake_ideal=False, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8ed82b-8d5a-4daa-b60f-59bb550a0219",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('truth_quantiles.txt', truth_quantiles.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92de4187-e8e1-468c-9c0e-68b4b53c5558",
   "metadata": {},
   "source": [
    "## Posterior-Predictive Check\n",
    "\n",
    "$PPC_{LL}=log(p(D_{new}|D))=log(\\int p(D_{new}|\\theta)*p(\\theta|D)d\\theta)$\n",
    "\n",
    "$=log(E_\\theta[p(D_{new})])$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906d1d1c-1df1-46b7-a0eb-64087b5c5ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_agnostic_BNN import log_posterior_predictive_check"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fecbb60-b678-41ba-a448-b420d0b1c108",
   "metadata": {},
   "source": [
    "## Scratch Space for Developing and Debugging:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c30a35-21c0-4d60-a544-4bae815eaa7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_iter = iter(val_data_loader)\n",
    "inputs, outputs = next(data_iter)\n",
    "print(f'{inputs.shape=}, {outputs.shape=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268c6611-bd09-48d3-ab0c-29779dcee999",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_mu, pred_sigma = torch.randn(5), torch.rand(5) #get_BNN_pred_distribution(model, inputs.to(model.device), n_samples=10)\n",
    "pred_distribution = torch.distributions.normal.Normal(pred_mu, pred_sigma)\n",
    "print(f'{pred_distribution=}')\n",
    "pred_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07615816-c86e-417f-9586-530aa4071bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = pred_distribution.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5608257e-52e9-4f66-bd0d-49c3d7788e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = samples[:, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2787cc5c-2a52-42b9-8807-49a45124f2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{outputs.shape=}')\n",
    "print(f'{samples.shape=}')\n",
    "print(f'{pred_distribution.loc.shape=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b689370f-98b6-4918-9f13-e1db661fe72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ll = pred_distribution.log_prob(outputs.to(model.device))\n",
    "print(f'{ll.shape=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b86a139-a449-47b8-808a-3e63dbcf1ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.distributions.normal.Normal(*pred_distribution, validate_args=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
