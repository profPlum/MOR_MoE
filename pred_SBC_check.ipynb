{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71861422-d351-4c20-84ef-657a5b175bed",
   "metadata": {},
   "source": [
    "# Setup:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458919a7-9007-4d9d-95ea-95386b12eb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pytorch_lightning as L\n",
    "import torch.nn.functional as F\n",
    "import torch.multiprocessing\n",
    "torch.multiprocessing.set_sharing_strategy('file_system')\n",
    "\n",
    "from lightning_utils import *\n",
    "from MOR_Operator import MOR_Operator\n",
    "from POU_net import POU_net\n",
    "import JHTDB_sim_op\n",
    "fields = lambda x: [name for name in vars(x) if not name.startswith('_')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31bb2d28-3ea5-4a2d-a278-395fe942cf02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(path, device='cuda:1', **kwd_args):\n",
    "    ''' Wraps up all the nonsense involved in loading an inference model properly into one function. '''\n",
    "    kwd_args = {'n_inputs': 3, 'n_outputs': 3, 'ndims': 3} | kwd_args # user-provided kwd_args has precedence in update\n",
    "    if 'VI' in path:\n",
    "        print('loading VI model!')\n",
    "        model = JHTDB_sim_op.PPOU_NetSimulator.load_from_checkpoint(path, **kwd_args)\n",
    "    else: \n",
    "        print('loading deterministic model!')\n",
    "        model = JHTDB_sim_op.POU_NetSimulator.load_from_checkpoint(path, **kwd_args)\n",
    "\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    # freeze everything\n",
    "    for parameter in model.parameters():\n",
    "        parameter.requires_grad=False\n",
    "    return model\n",
    "\n",
    "model = load_model('best_VI_model3.ckpt')\n",
    "#model = load_model('best_model3.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc3625f-cc99-4437-82cb-bc3f72be3503",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = JHTDB_sim_op.JHTDB_Channel('data/turbulence_output', time_chunking=5)\n",
    "val_data_loader = torch.utils.data.DataLoader(val_dataset, batch_size=5, num_workers=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd658932-4b37-43c3-a945-b70798fefa0d",
   "metadata": {},
   "source": [
    "# Predictive Simulation Based Calibration (aka PSBC)\n",
    "First update `get_BNN_pred_distribution()` to work with aleatoric moment outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6fb063-2a9b-47c5-8fa7-fbfe379b98b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_cache():\n",
    "    ''' clear pytorch cuda cache '''\n",
    "    import torch, gc\n",
    "    while gc.collect(): pass\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "# Adapted to stack aleatoric moments\n",
    "def get_BNN_pred_distribution(bnn_model, x_input, n_samples=100, no_grad=True):\n",
    "    '''\n",
    "    If you just want moments use get_BNN_pred_moments() instead as it is *much* more memory efficient (e.g. for large sample sizes). But this is still useful if you want an actual distribution.\n",
    "    '''\n",
    "    if no_grad:\n",
    "        with torch.inference_mode():\n",
    "            return get_BNN_pred_distribution(bnn_model, x_input, n_samples, no_grad=False)\n",
    "    preds_mu, preds_sigma = [], []\n",
    "    x_input = x_input.to(model.device)\n",
    "    for i in range(n_samples):\n",
    "        mu, sigma = bnn_model(x_input)\n",
    "        preds_mu.append(mu)\n",
    "        preds_sigma.append(sigma)\n",
    "    preds_mu = torch.stack(preds_mu, axis=0)\n",
    "    preds_sigma = torch.stack(preds_sigma, axis=0)\n",
    "    return preds_mu, preds_sigma\n",
    "\n",
    "import numpy as np\n",
    "dumb_vmap = lambda func: lambda X: torch.stack([func(x) for x in X])\n",
    "# useful for debugging when vmap won't work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51577e62-2a7a-4a78-9e2f-f3021a4baeda",
   "metadata": {},
   "source": [
    "## ALeatoric KDE Equations:\n",
    "\n",
    "1. We want to take the union of the centroid pdfs so we sum. But then we need to make the pdf integrate to 1 $\\int_{x \\in \\Omega} p(x) dx=1$, so we divide by the number of pdfs resulting in an average: $$p(S_{jk})={1\\over N}\\sum^N_{i=0}p_{ik}(S_{jk}) \\text{ s.t. } S_{jk}\\sim p_{jk}$$\n",
    "2. However all these computations need to happen in the log domain for numerical stability: $$log(p(S_{jk}))=log({1\\over N}\\sum^N_{i=0}p_{ik}(S_{jk}))=log(\\sum^N_{i=0}p_{ik}(S_{jk}))-log(N)$$\n",
    "4. In practice this requires the Log-sum-exp trick (aka LSE): $$log(p(S_{jk}))={LSE}^N_{i=0}log(p_{ik}(S_{jk}))-log(N)$$\n",
    "5. Then we need to get the joint pdf across all the spatial dimension(s) (indexed by k) $$log(p(S_j))=\\sum_k log(p(S_{jk}))$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad62986-d2ab-4866-8f6a-78a12fcebc1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GOTCHA: It seems the problem is that it always gives more liklihood to the true value than the samples? Maybe just sample more?\n",
    "# That wouldn't be all bad if it were actually true it would imply that the true value always has the highest likelihood but it can't be literally true...\n",
    "def _find_batch_BCI_truth_quantiles(model, inputs, outputs, n_samples_per_batch, chunk_size=25, fake_ideal=False, verbose=True):\n",
    "    with torch.inference_mode():\n",
    "        # get sample aleatoric distributions from sampling epistemic distribution\n",
    "        pred_distribution = get_BNN_pred_distribution(model, inputs, n_samples=n_samples_per_batch)\n",
    "        pred_distribution = torch.distributions.normal.Normal(*pred_distribution, validate_args=False)\n",
    "        pred_samples = pred_distribution.sample() # then sample the actual predictions from the sampled aleatoric distributions\n",
    "        if verbose: print('pred_samples.shape:', pred_samples.shape) # shape==[aleatoric_sample, batch, ...]\n",
    "\n",
    "        def get_log_density(sample_datum):\n",
    "            ''' gets log density of a single sample given the aleatoric distributions sampled from the epistemic weights '''\n",
    "            # averaged_pdfs = p(S_jk) = (1/N)∑_i(p_ik(S_jk)) s.t. S_jk ~ p_jk := KDE-style pdf (derived from aleatoric distributions)\n",
    "            averaged_pdfs = torch.logsumexp(pred_distribution.log_prob(sample_datum), dim=0) - np.log(n_samples_per_batch) # average across epistemic dimension\n",
    "            joint_pdfs = torch.vmap(torch.sum)(averaged_pdfs) # joint pdf across all non-batch dims := log(∏_ip_i(S_i))\n",
    "            return joint_pdfs\n",
    "\n",
    "        # vmap supports additional input dimension: j (aka aleatoric sample dimension)\n",
    "        #vget_log_density = dumb_vmap(get_log_density)\n",
    "        vget_log_density = torch.vmap(get_log_density, chunk_size=chunk_size)\n",
    "        pred_samples = pred_samples[:, None] # move the aleatoric sample dimension out of the epistemic sample distribution dimension\n",
    "        assert tuple(pred_samples.shape)[:3]==(n_samples_per_batch, 1, inputs.shape[0])\n",
    "        pred_joint_log_pdfs = vget_log_density(pred_samples) # shape==[aleatoric_sample, batch]\n",
    "        assert tuple(pred_joint_log_pdfs.shape)==(n_samples_per_batch, inputs.shape[0])\n",
    "        \n",
    "        import random # Verified that fake ideal works: 10/10/24\n",
    "        if fake_ideal: # artificially simulate the ideal case where outputs are sampled from prediction distribution\n",
    "            outputs = random.choice(pred_samples) # GOTCHA: isn't realized with small number of batches & sample sizes!\n",
    "\n",
    "        truth_joint_log_pdf = get_log_density(outputs[None])\n",
    "        assert tuple(truth_joint_log_pdf.shape)==(inputs.shape[0],)\n",
    "\n",
    "        if verbose:\n",
    "            # plot the pdf quantile distribution(s)\n",
    "            batch_display_ids = random.choices(range(inputs.shape[0]), k=1)\n",
    "            for i in batch_display_ids:\n",
    "                plt.hist(pred_joint_log_pdfs[:,i].cpu(), color='blue')\n",
    "                plt.axvline(truth_joint_log_pdf[i].item(), color='red')\n",
    "                plt.title(f'{i}th joint-log-pdf Distribution')\n",
    "                plt.show()\n",
    "\n",
    "        pdf_comparison = pred_joint_log_pdfs<=truth_joint_log_pdf\n",
    "        if verbose: print(f'pdf_comparison={list(pdf_comparison.ravel().cpu().numpy())}')\n",
    "        truth_quantiles = torch.sum(pdf_comparison, dim=0)/pdf_comparison.shape[0]\n",
    "        assert pred_joint_log_pdfs.shape[0]==pdf_comparison.shape[0]==n_samples_per_batch\n",
    "        return truth_quantiles.cpu().detach()\n",
    "\n",
    "# Actually we don't need KDE! We can use the aleatoric uncertainty to get density directly!\n",
    "def find_BCI_truth_quantiles(model, data_loader, n_batches=100, n_samples_per_batch=25, chunk_size=25, fake_ideal=False, verbose=True):\n",
    "    \"\"\"\n",
    "    These quantiles should follow q~U(0,1) in order for BCI theory to be satisfied.\n",
    "    You can simulate the ideal case as a sanity check with fake_ideal=True.\n",
    "    GOTCHA: In practice with small batch and/or sample sizes even with fake_ideal=True, the distribution will not look uniform!\n",
    "    GOTCHA: This is still not the most rigorous implementation! That would sort based on KDE-density rather than centroid distance.\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    assert model.device.type=='cuda' # TOO slow on cpu\n",
    "    truth_quantiles = []\n",
    "    while len(truth_quantiles)<n_batches:\n",
    "        for inputs, outputs in data_loader:\n",
    "            if len(truth_quantiles)==0: print(f'{inputs.shape=}, {outputs.shape=}')\n",
    "            elif len(truth_quantiles)==n_batches: break\n",
    "            print(f'processing batch: {len(truth_quantiles)}')\n",
    "            truth_quantiles.append(_find_batch_BCI_truth_quantiles(model, inputs.to(model.device), outputs.to(model.device),\n",
    "                                                                   n_samples_per_batch=n_samples_per_batch, fake_ideal=fake_ideal,\n",
    "                                                                   chunk_size=chunk_size, verbose=verbose))\n",
    "\n",
    "    truth_quantiles = torch.cat(truth_quantiles)\n",
    "    display_quantiles = list(torch.quantile(truth_quantiles, q=torch.linspace(0.0,1.0, steps=5)).numpy())\n",
    "    print('1/5th quantiles of truth quantile distribution: ', display_quantiles)\n",
    "    plt.hist(truth_quantiles)\n",
    "    plt.title('Truth Quantiles (Should follow q~U(0,1))')\n",
    "    plt.show()\n",
    "    return truth_quantiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0fff30-a765-4048-aee3-ba909f92a024",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pdb on\n",
    "truth_quantiles = find_BCI_truth_quantiles(model, val_data_loader, n_batches=10, n_samples_per_batch=25, fake_ideal=False, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8ed82b-8d5a-4daa-b60f-59bb550a0219",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('truth_quantiles.txt', truth_quantiles.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92de4187-e8e1-468c-9c0e-68b4b53c5558",
   "metadata": {},
   "source": [
    "## Posterior-Predictive Check\n",
    "\n",
    "$PPC_{LL}=log(p(D_{new}|D))=log(\\int p(D_{new}|\\theta)*p(\\theta|D)d\\theta)$\n",
    "\n",
    "$=log(E_\\theta[p(D_{new})])$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906d1d1c-1df1-46b7-a0eb-64087b5c5ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_posterior_predictive_check(model, val_data_loader, n_samples = 100):\n",
    "    PPC_LL = 0\n",
    "    with torch.inference_mode():\n",
    "        for i in range(n_samples):\n",
    "            for X, y in val_data_loader:\n",
    "                mu, sigma = model(X.to(model.device))\n",
    "                normal = torch.distributions.normal.Normal(mu, sigma)\n",
    "                PPC_LL = torch.logaddexp(PPC_LL, normal.log_prob(y.to(model.device)).sum())\n",
    "        PPC_LL = PPC_LL-torch.log(n_samples*len(val_data_loader.dataset))\n",
    "    PPC_LL = PPC_LL.item()\n",
    "    print(f'{PPC_LL=}')\n",
    "    return PPC_LL\n",
    "log_posterior_predictive_check(model, val_data_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fecbb60-b678-41ba-a448-b420d0b1c108",
   "metadata": {},
   "source": [
    "## Scratch Space for Developing and Debugging:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c30a35-21c0-4d60-a544-4bae815eaa7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_iter = iter(val_data_loader)\n",
    "inputs, outputs = next(data_iter)\n",
    "print(f'{inputs.shape=}, {outputs.shape=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268c6611-bd09-48d3-ab0c-29779dcee999",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_mu, pred_sigma = get_BNN_pred_distribution(model, inputs.to(model.device), n_samples=10)\n",
    "pred_distribution = torch.distributions.normal.Normal(pred_mu, pred_sigma)\n",
    "print(f'{pred_distribution=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07615816-c86e-417f-9586-530aa4071bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = pred_distribution.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5608257e-52e9-4f66-bd0d-49c3d7788e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = samples[:, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2787cc5c-2a52-42b9-8807-49a45124f2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{outputs.shape=}')\n",
    "print(f'{samples.shape=}')\n",
    "print(f'{pred_distribution.loc.shape=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b689370f-98b6-4918-9f13-e1db661fe72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ll = pred_distribution.log_prob(outputs.to(model.device))\n",
    "print(f'{ll.shape=}')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
